package tekno;

import java.util.Arrays;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;



/**
 * This class stores a representation of the graph in Java. By adding an SRO triple, it builds a graph abstraction, by memorizing the nodes and the edges (without duplicates). In this class are also implemented methods to discover aliases (not already discovered by coreference resolution) based on the term’s Wikipedia Page ID: if two different terms have the same page ID they are aliases. 
 *
 */
public class Relations {
	

	
	private Map<Integer, String> nodes = new HashMap<Integer, String>();
	private Map<Integer[], String> edges = new HashMap<Integer[], String>();
	private Map<String, Integer> wikiMatches = new HashMap<String, Integer>();
	private List<String> removePronouns = Arrays.asList("i","me","you","he", "she", "it", "him","her","his","we","us","they","them");


	
	/**
	 * this is the main method of the class;
	 * First if the subject or the object of the triple are a pronoun contained in the attribute removePronouns, it returns (this is done to avoid having connections in the graph that are referred to an unknown entity). 
Then if the node Map attribute is empty it automatically adds a node for the subject and object and an edge which connects them; the ids for the nodes are generated by hashing the name of the nodes (only positive integer). This ids, obtained with hashing, are needed in order to optimize the search for duplicates.
If not empty, the method checks for aliases, already inserted in the nodes Map, by cycling through and confronting the current node with the nodes to be inserted (both for subject and object). If a match is found, the node is added, but a new edge (for the alias relationship) is inserted between the matched nodes. If the match is not found, it simply adds the nodes to the Map and at the end inserts an edge for the relationship specified in the input. 
	 * @param s subject 
	 * @param r relation
	 * @param o object
	 */
	public void addRelation(String s, String r, String o) {
		int s_id = s.hashCode() & 0xfffffff;
		int o_id = o.hashCode() & 0xfffffff;
				
		
		if(removePronouns.contains(s.toLowerCase()) || removePronouns.contains(o.toLowerCase()))
			return ;
		
		if(nodes.isEmpty())
		{
			nodes.putIfAbsent(s_id, s);
			nodes.putIfAbsent(o_id, o);
	
		} else {
			Map<Integer, String> newNodes = Map.copyOf(nodes);
			boolean s_f = false, o_f = false;
			for(Map.Entry<Integer, String> e: newNodes.entrySet() )
			{
				if(matchPageId(e.getValue(), s)) {
					nodes.putIfAbsent(s_id, s);
					if(s_id != e.getKey())
						edges.put(new Integer[] {s_id, e.getKey()}, "alias");
					s_id = e.getKey();
					s_f = true;
				}
				
				if(matchPageId(e.getValue(), o)) {
					nodes.putIfAbsent(o_id, o);
					if(o_id != e.getKey())
						edges.put(new Integer[] {o_id, e.getKey()}, "alias");
					o_id = e.getKey();
					o_f = true;
				}
				
				if(s_f && o_f) break;
				if(!s_f)
					nodes.putIfAbsent(s_id, s);
				if(!o_f)
					nodes.putIfAbsent(o_id, o);
			}
		}
		
		edges.put(new Integer[] {s_id, o_id}, r.replace(":", "_"));
	}
	
	
	
	/**
	 * this method performs the searches on Wikipedia to return true, if the two Strings in input match the same Wiki Page, false otherwise. To do this in an optimized way, it uses the attribute WikiMatches to check if a search has already performed for that specific String; if not, it performs the search (this is delegated to the WikipediaIntegration Class), and adds the result to the Map.   
	 * @param s1 first term to search
	 * @param s2 second term to search
	 * @return true if the two terms correspond to the same Wikipedia page (ID), false otherwise
	 */
	private boolean matchPageId(String s1, String s2) {
		int id1 = -1, id2 = -1;
		if(wikiMatches.containsKey(s1)) id1 = wikiMatches.get(s1);
		else {
			id1 = WikipediaIntegration.getWikiID(s1);
			wikiMatches.putIfAbsent(s1, id1);
		}
		if(wikiMatches.containsKey(s2)) id2 = wikiMatches.get(s2);
		else {
			id2 = WikipediaIntegration.getWikiID(s2);
			wikiMatches.putIfAbsent(s2, id2);
		}

		return (id1==id2) && (id1!=-1 || id2!=-1);
	}


	/**
	 * this method prints all the edges currently inserted. It is only used for debugging purposes.

	 */
	public void printEdges() {
		edges.forEach((c, t) -> {
			System.out.println(c[0] + " - " + t + " -> "+c[1]);
		});
	}
	
	/**
	 * this method prints all the nodes currently inserted. It is only used for debugging purposes.

	 */
	public void printNodes() {
		nodes.forEach((i, n) -> {
			System.out.println(i + " - " + n );
		});	
	}


	
	

	/**
	 * @return the Iterator for the edges attribute Map.

	 */
	public Iterator<Entry<Integer[], String>> edgeIterator() {
		return this.edges.entrySet().iterator();
	}
	
	/**
	 * @return the Iterator for the edges attribute Map.
	 */
	public Iterator<Entry<Integer, String>> nodeIterator() {
		return this.nodes.entrySet().iterator();
	}



}
